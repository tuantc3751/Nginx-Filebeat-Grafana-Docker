version: "3.2"

services:
    elasticsearch:
        build:
            context: elasticsearch/
            args:
                ELK_VERSION: $ELK_VERSION
        container_name: elasticsearch
        volumes:
            - type: bind
              source: ./elasticsearch/config/elasticsearch.yml
              target: /usr/share/elasticsearch/config/elasticsearch.yml
              read_only: true
            - type: volume
              source: elasticsearch
              target: /usr/share/elasticsearch/data
        ports:
            - "9200:9200"
            - "9300:9300"
        environment:
            - cluster.name=docker-cluster
            - bootstrap.memory_lock=true
            - "ES_JAVA_OPTS=-Xms1G -Xmx1G"
            - xpack.security.enabled=false
            - "discovery.type=single-node"
            # ES_JAVA_OPTS: "-Xmx256m -Xms256m"
            # ELASTIC_PASSWORD: changeme
        networks:
            - elk

    app:
        build: ./app
        volumes:
            - ./app/:/usr/src/app
            - /usr/src/app/node_modules/ # make node_module empty in container
        command: npm start
        ports:
            - "3000:3000"
        networks:
            - elk

    nginx:
        build: ./nginx
        container_name: nginx
        volumes:
            - ./nginx/config:/etc/nginx/conf.d
            - ./nginx/log:/var/log/nginx
        ports:
            - "80:80"
            - "443:443"
        links:
            - app:app
        depends_on:
            - app
        networks:
            - elk

    filebeat:
        build: ./filebeat
        container_name: filebeat
        entrypoint: "filebeat -e -strict.perms=false"
        volumes:
            - ./filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml
            - ./nginx/log:/var/log/nginx
        networks:
            - elk
        depends_on:
            - app
            - nginx
            - elasticsearch
        # links:
        #     - logstash

    zookeeper:
        restart: always
        container_name: zookeeper
        hostname: zookeeper
        image: confluentinc/cp-zookeeper:7.3.10
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        ports:
            - 2181:2181
        networks:
            - elk
        healthcheck:
            test: ps aux | grep zookeeper
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 120s

    kafka:
        container_name: kafka
        hostname: kafka
        restart: always
        image: confluentinc/cp-kafka:7.3.10
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        ports:
            - 9092:9092
        networks:
            - elk
        depends_on:
            zookeeper:
                condition: service_healthy
        healthcheck:
            test: ps aux | grep kafka
            interval: 30s
            timeout: 10s
            retries: 3
            start_period: 120s

    # zookeeper:
    #     image: wurstmeister/zookeeper:latest
    #     hostname: zookeeper
    #     container_name: zookeeper
    #     restart: unless-stopped
    #     ports:
    #         - 2181:2181
    #     networks:
    #         - elk

    # kafka:
    #     image: wurstmeister/kafka:latest
    #     hostname: kafka
    #     container_name: kafka
    #     restart: unless-stopped
    #     depends_on:
    #         - zookeeper
    #     ports:
    #         - 9092:9092
    #     environment:
    #         KAFKA_ADVERTISED_HOST_NAME: 192.168.22.1
    #         KAFKA_ADVERTISED_PORT: 9092
    #         KAFKA_CREATE_TOPICS: nginx123:1:1
    #         KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    #     networks:
    #         - elk

    python-consumer:
        build:
            context: ./python
        container_name: python
        depends_on:
            - kafka # Phụ thuộc vào Kafka
            - elasticsearch
        networks:
            - elk # Đặt vào cùng mạng 'elk' để giao tiếp với Kafka
        restart: always

    grafana:
        image: grafana/grafana:11.2.0
        container_name: grafana
        ports:
            - 3001:3000
        restart: unless-stopped
        environment:
            GF_SECURITY_ADMIN_USER: admin
            GF_SECURITY_ADMIN_PASSWORD: admin
        depends_on:
            - elasticsearch
        volumes:
            - ./data/grafana_storage:/var/lib/grafana
        networks:
            - elk

    kibana:
        build:
            context: kibana/
            args:
                ELK_VERSION: $ELK_VERSION
        container_name: kibana
        volumes:
            - type: bind
              source: ./kibana/config/kibana.yml
              target: /usr/share/kibana/config/kibana.yml
              read_only: true
        ports:
            - "5601:5601"
        networks:
            - elk
        depends_on:
            - elasticsearch

networks:
    elk:
        driver: bridge

volumes:
    elasticsearch:
